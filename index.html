<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Yuma Tsuboi</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Custom styles for this template -->
    <link href="css/agency.min.css" rel="stylesheet">

  </head>

  <body id="page-top">

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark fixed-top" id="mainNav">
      <div class="container">
        <a class="navbar-brand js-scroll-trigger" href="#page-top">Yuma Tsuboi</a>
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          Menu
          <i class="fa fa-bars"></i>
        </button>
        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#portfolio">Portfolio</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#about">About</a>
            </li>
            <li class="nav-item">
              <a class="nav-link js-scroll-trigger" href="#history">Experience</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Header -->
    <header class="masthead">
      <div class="container">
        <div class="intro-text">
          <div class="row">
            <div class="col-sm-4">
              <div class="team-member">
                <!-- Blank placeholder for padding -->
              </div>
            </div>
            <div class="col-sm-4">
              <div class="team-member">
                <img class="mx-auto rounded-circle" src="img/yuma/profile_sharp.jpg" alt="">
              </div>
            </div>
            <div class="col-sm-4">
              <div class="team-member">
                <!-- Blank placeholder for padding -->
              </div>
            </div>
          </div>
          <div class="intro-lead-in">Hello! こんにちは! 你好! Bonjour!</div>
          <div class="intro-heading">I'm Yuma Tsuboi</div>
          <h3>Software Engineer・Social Robotics・Product Management</h3>
          <br>
          <ul class="list-inline social-buttons">
              <li class="list-inline-item">
                <a href="https://www.linkedin.com/in/yumatsuboi/">
                  <img src="img/icons/png/linkedin-inverted.png" height="60" width="60" alt="">
                </a>
              </li>
              <li class="list-inline-item">
                <a href="https://yumatsuboi.blogspot.ca/">
                  <img src="img/icons/png/blogger-inverted.png" height="60" width="60" alt="">
                </a>
              </li>
              <li class="list-inline-item">
                <a href="https://github.com/zyuma">
                  <img src="img/icons/png/github-inverted.png" height="60" width="60" alt="">
                </a>
              </li>
            </ul>
          <br>
          <!-- Button -->
          <!--
          <div class="col-lg-12 text-center">
            <div id="success"></div>
            <button id="sendMessageButton" class="btn btn-xl" type="submit">Resume</button>
          </div>
          -->
        </div>
      </div>
    </header>

    <!-- Portfolio Grid -->
    <section class="bg-light" id="portfolio">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Portfolio</h2>
            <h3 class="section-subheading text-muted">Current endeavours and recent projects</h3>
          </div>
        </div>

        <div class="row">

          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal1">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fa fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/deep_learning/udacity.png" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Deep Learning Course</h4>
              <p class="text-muted">TensorFlow, Machine Learning, Python</p>
            </div>
          </div>

          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal2">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fa fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/prod_mng/productmanagemtn.png" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Product Management</h4>
              <p class="text-muted">10-week Bootcamp @ Brainstation</p>
            </div>
          </div>

          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal3">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fa fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/toastmasters/logo.png" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Toastmasters</h4>
              <p class="text-muted">Public Speaking and Facilitation</p>
            </div>
          </div>

          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal4">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fa fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/emotion_recognition/4_thumbnail.jpg" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Social Robotics</h4>
              <p class="text-muted">Master Thesis, Machine Learning</p>
            </div>
          </div>

          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal5">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fa fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/breathing_instructor/breathinginstructor_thumbnail.png" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Guided Breathing App</h4>
              <p class="text-muted">Android, Java, UX Design</p>
            </div>
          </div>

          <div class="col-md-4 col-sm-6 portfolio-item">
            <a class="portfolio-link" data-toggle="modal" href="#portfolioModal6">
              <div class="portfolio-hover">
                <div class="portfolio-hover-content">
                  <i class="fa fa-plus fa-3x"></i>
                </div>
              </div>
              <img class="img-fluid" src="img/portfolio/pipe_inspection_robot/robot_side_thumbnail.jpg" alt="">
            </a>
            <div class="portfolio-caption">
              <h4>Autonomous Robot</h4>
              <p class="text-muted">Engineering Design</p>
            </div>
          </div>

        </div>
      </div>
    </section>

    <!-- About -->
    <section id="about">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">About</h2>
            <h3 class="section-subheading text-muted"></h3>
          </div>
        </div>
        <div class="row">
          <div class="col-lg-12">
            <div class="row">
              <div class="col-md-7">
                <div class="timeline-body">

                  <p>I’m a Software Engineer in Toronto working at SapientRazorfish, a tech consulting firm, on the Walmart.ca E-commerce account. I’m a developer for the Play framework that integrates the customer frontend with backend data that includes Endeca CRM, Oracle ATG, multiple inventory datacenters and numerous microservices. My work involves writing Scala code for request-response orchestration, data models, developing new backend services and implementing architecture enhancements to expand customer experience.</p>

                  <p>Learning is a lifelong process. To prepare for my long-term goal of becoming a Product Manager, I spend my free time on developing leadership and management skills. Specifically, I am taking Product Management at a Coding Bootcamp to learn Product Strategies and Software Development Processes and I regularly attend Toastmasters to practice Public Speaking and Meeting Facilitation.</p>

                  <p>My path to SW Development has been one with many interesting turns. Attracted by cutting-edge tech and rewarding challenges, I entered the multidisciplinary Engineering Science program at UofT. I majored in ECE in 3rd year, which led me to a 12-month internship at AMD HQ in Sunnyvale, California. Inspired by the mobile app boom in Silicon Valley, I spent my spare time studying CS concepts. In my final year of undergrad, I specialized in SW Engineering and wrote a thesis on Mobile Application for Smoking Cessation. The AI and Machine Learning courses during that time motivated me to pursue a Master's at UofT with research focus on Human-Robot Interaction and wrote a thesis on providing care for the aging population with Social Robots.</p>

                  <p>I am fluent in both Japanese and English from my childhood spent in Japan and Canada. I was never big on learning a new language, but the multilingual people I met during backpacking in Europe has led me to become a lifelong learner of French and Mandarin, as a Canadian with a Japanese-Chinese background.</p>

                </div>
                
              </div>
              <div class="col-md-5">
                <div class="timeline-heading">
                  <img class="img-fluid d-block mx-auto" src="img/about/swiss.jpeg" alt="">
                  <br>
                  <img class="img-fluid d-block mx-auto" src="img/about/lab.jpg" alt="">
                  <br>
                  <img class="img-fluid d-block mx-auto" src="img/about/coach.jpg" alt="">
                </div>
              </div>
              
            </div>
          </div>
      </div>
    </section>

    <!-- Experience -->
    <section class="bg-light" id="history">
      <div class="container">
        <div class="row">
          <div class="col-lg-12 text-center">
            <h2 class="section-heading">Experience</h2>
            <h3 class="section-subheading text-muted"></h3>
          </div>
        </div>
        <div class="row">
          <div class="col-lg-12">


            <!-- Experience 1 -->
            <div class="row">
              <div class="col-md-5">
                <div class="timeline-heading">
                  <h4>Software Engineer</h4>
                  <h4><a href="https://www.sapientrazorfish.com/">SapientRazorfish</a></h4>
                  <h5 class="text-muted">Mar 2017 - Present</h5>
                </div>
              </div>
              <div class="col-md-7">
                <div class="timeline-body">
                  <p class="text-muted">I’m a developer on the Walmart retainer account of 60 people, working on enhancing the high-traffic E-commerce platform used by Walmart. I work with Play framework with Scala that integrates the customer frontend view with backend data sources that include Endeca CRM, Oracle ATG, multiple inventory datacenters and numerous microservices. Hence, my day-to-day job involves request-response orchestration, tailoring data models, developing new backend services and enhancements to the solution architecture to expand customer experience. Aside from the developmental tasks, I’m enthusiastic about bootcamp sessions to do a knowledge transfer of the Play architecture that is black-boxed to other disciplines in the team and lead meetings to advance and breakdown stories in the backlog.
</p>
                </div>
              </div>
            </div>
            <br>

            <!-- Experience 2 -->
            <div class="row">
              <div class="col-md-5">
                <div class="timeline-heading">
                  <h4>Product Management</h4>
                  <h4><a href="https://brainstation.io/course-package/product-management/toronto#Overview">Brainstation</a></h4>
                  <h5 class="text-muted">Sep 2017 - Present</h5>
                </div>
              </div>
              <div class="col-md-7">
                <div class="timeline-body">
                  <p class="text-muted">This is a 10-week bootcamp course offered by a Brainstation, which covers a wide range of PM concepts such as Product canvas, vision statements, product strategy, market research, MVP, agile methods, lean UX, wireframing, product market fit, roadmapping, risk management, financial planning, pricing strategy and customer metrics. I found the various frameworks introduced in the course to be useful in grasping the often intangible concepts in Product Management. The course was taught by Tom Levesque (Co-founder of rey.ai) and Eril Berkok (Product Manager at Unata Inc) who are very enthusiastic and experienced in this field.
</p>
                </div>
              </div>
            </div>
            <br>

            <!-- Experience 3 -->
            <div class="row">
              <div class="col-md-5">
                <div class="timeline-heading">
                  <h4>Master of Engineer</h4>
                  <h4><a href="http://asblab.mie.utoronto.ca/">Univ of Toronto - ASB Lab</a></h4>
                  <h5 class="text-muted">2015 - 2016</h5>
                </div>
              </div>
              <div class="col-md-7">
                <div class="timeline-body">
                  <p class="text-muted">Under the supervison of Prof Goldie Nejat (Canada Research Chair in Robots for Society, Dir of Institute for Robotics and Mechatronics at UofT), I worked on improving AI prediction of emotion during interaction with people from their vocal intonation. This AI was combined with other modes of emotion inference, body language and facial expression, to make the most informed prediction. The motivation is to increase the emotional intelligence of robots to enable them to socialize better with people, specifically to perform in caregiving context for the aging population. With a tech stack of Weka, Python and Matlab, I developed an AI that achieved 82% accuracy with Neural Networks in cross-validation, which was installed on a NAO Robot to be tested with real human interaction. During the year I took several graduate courses including Intelligent Robotics for Society, Statistical Analysis & Experimental Methods and  Leadership with Emotional Intelligence.</p>

                </div>
              </div>
            </div>
            <br>

            <!-- Experience 4 -->
            <div class="row">
              <div class="col-md-5">
                <div class="timeline-heading">
                  <h4>CAD Software Engineer Intern</h4>
                  <h4><a href="https://www.amd.com/en/home">AMD</a></h4>
                  <h5 class="text-muted">2013 - 2014</h5>
                </div>
              </div>
              <div class="col-md-7">
                <div class="timeline-body">
                  <p class="text-muted">My work included performing regular regression on the Chip Design CAD system, reporting bugs and implementing fixes in an agile development process. I also took on Web related projects to automate the publishing of the regression results to internal wiki page.
</p>
                </div>
              </div>
            </div>  
            <br>

            <!-- Experience 5 -->
            <div class="row">
              <div class="col-md-5">
                <div class="timeline-heading">
                  <h4>Engineering Science</h4>
                  <h4><a href="http://engsci.utoronto.ca/explore_our_program/about_engsci/">Univ of Toronto</a></h4>
                  <h5 class="text-muted">2010 - 2015</h5>
                </div>
              </div>
              <div class="col-md-7">
                <div class="timeline-body">
                  <p class="text-muted">In the first 2 years of foundation in Engineering, I took variety of courses that ranged from Fluid Dynamics and Quantum Mechanics to Computer Organization and Robot Design. In the third year I majored in Electrical and Computer Engineering, which included Signal Processing and Operating System course. In my final year I focused on Software Engineering courses, which included Computer Security and Machine Learning. Aldo during my final year I wrote a Bachelor’s Thesis on Mobile Application in Smoking Cessation under the supervision of Prof Jonathan Rose, collaborating with clinicians from the Centre of Mental Health and Addiction (CAMH).</p>
                </div>
              </div>
            </div>  
            <br>

            <div class="clearfix"></div>

              
          </div>
        </div>
      </div>
    </section>

    <!-- Footer -->
    <footer>
      <div class="container">
        <div class="row">
          <div class="col-md-4">
            <span class="copyright">Copyright &copy; Yuma Tsuboi 2017</span>
          </div>
          <div class="col-md-4">
            <ul class="list-inline social-buttons">
              <li class="list-inline-item">
                <a href="https://www.linkedin.com/in/yumatsuboi/">
                  <img src="img/icons/png/linkedin-inverted.png" height="60" width="60" alt="">
                </a>
              </li>
              <li class="list-inline-item">
                <a href="https://yumatsuboi.blogspot.ca/">
                  <img src="img/icons/png/blogger-inverted.png" height="60" width="60" alt="">
                </a>
              </li>
              <li class="list-inline-item">
                <a href="https://github.com/zyuma">
                  <img src="img/icons/png/github-inverted.png" height="60" width="60" alt="">
                </a>
              </li>
            </ul>
          </div>
          <div class="col-md-4">
            <ul class="list-inline quicklinks">
              <li class="list-inline-item">
                <a href="#">Privacy Policy</a>
              </li>
              <li class="list-inline-item">
                <a href="#">Terms of Use</a>
              </li>
            </ul>
          </div>
        </div>
      </div>
    </footer>

    <!-- Portfolio Modals -->

    <!-- Modal 1 -->
    <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2>Deep Learning</h2>
                  <p class="item-intro text-muted">Course by Udacity + Google.</p>
                  
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/deep_learning/instructor.png" alt="">

                  <p>My Master’s thesis in social robotics was an application of Machine Learning, a classification of emotions from voice signal features. With the undergraduate level Machine Learning knowledge, I was able to build on it through literature review, discussions with my grad school peers and experimentation. Further structured learning of Machine Learning was something that escaped me, especially now that I’m out of the academia environment and working full-time as an e-commerce software developer.</p>

                  <p>Pursuing the bleeding edge technology have always benefitted me, and as Wayne Gretzky says, “Skate to where the puck is going to be, not where it has been”, I need to learn more about the hottest tech of today without a doubt, Deep Learning. It’s a branch of Machine Learning and thankfully, I have the prerequisites to learn it and there’s no reason not to take advantage.</p>

                  <p>Here's the curriculrum:</p>

                  <img class="img-fluid d-block mx-auto" src="img/portfolio/deep_learning/agenda.png" alt="">

                  <p>The initial motivation given by Vincent Vanhoucke, Principal Scientist @ Google is certainly grasping and with my experience writing the motivation of my applied machine learning research in my Master’s thesis, I cannot agree with him more. In the future, coding skill will simply be a tool to learn the novelty of machine learning solution to problems in the world. </p>

                  <p>I loved his presentation of the need to optimize the loss function to basic logistic classification problems. Great review as it’s been a while and this seems promising! I will be making blog posts as I find well-explained concepts worth sharing.</p>

                  <p>Happy learning!</p>
                  <ul class="list-inline">
                    <li>Date: Nov 2017</li>
                    <li>Category: Machine Learning, Software Engineering, Personal Development</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 2 -->
    <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2>Product Management</h2>
                  <p class="item-intro text-muted">10-week Bootcamp @ Brainstation.</p>
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/01-full.jpg" alt="">
                  <p>My long-term goal is to transition towards management in the field of tech. But there are project management, technical management, site reliability management, etc... too many out there! To avoid spending too much time on contemplation, I decided to break and ice and just dive in, by taking a bootcamp course for PRODUCT Management! The Product Owners in my Scrum team at work are the ones who bring in the business needs in the form of developement tickets and I want to know how they came up with those. Learn more about the course curriculum here:
                    <br>
                    <a href="https://brainstation.io/course-package/product-management/toronto">Product Management Fall 2017 @ Brainstation Course Package</a> 
                  </p>
                  <p>Also, check out the mid-term presentation of our product, 2018 Worldcup Bars! We received many feedbacks, leading to great ideas for pivoting!</p>
                  <a href="https://photos.app.goo.gl/sBU7mpIyk5j7UqDg2">Midterm presentation</a> 
                  <ul class="list-inline">
                    <li>Date: November 2017</li>
                    <li>Category: Personal Development, Product Management</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 3 -->
    <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2>Toastmasters</h2>
                  <p class="item-intro text-muted">Public Speaking, Facilication, Leadership.</p>
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/toastmasters/description.png" alt="">
                  <p>Public speaking was never my forte. There were many times when I had to do a presentations but I hated it. At the same time I had the biggest respect for those who are amazing at public speaking and was envious of them. My long-term goal of transition to management asks for outstanding leadership, communication and facilitation skills. It was time to conquer my fears and take action to improve my weakness. Toastmasters is a great club to join to work on public speaking, meeting facilitation and listening/evaluation skills. Every week I participate in Toastmaster meetings to play a role such as Toastmaster (MC), Tabletopic master, Speech Evaluator, Timer, Grammarian and participate in impromptu speeches. On 1-2 months basis I do a prepared speech by following the Competent Communicator (CC) track, thus far completing 5 projects.
                  <br>
                  I began to video record my performances after 6 months as a way to break through the plateau and face my own shortcomings. Currently, I am using these videos as a way of blogging my journey of development. Check it out here:
                  <br>
                  <a href = "https://yumatsuboi.blogspot.ca/search/label/Toastmasters">Yuma Tsuboi's Toastmasters Blog</a>
                  <br>
                  And while you're here, check out my latest, CC5: Your body speaks!
                  </p>
                  <br>
                  <iframe width="560" height="315" src="https://www.youtube.com/embed/E25qRc-mYGk" frameborder="0" allowfullscreen></iframe>
                  <br>  
                  <ul class="list-inline">
                    <li>Date: Mar 2017 - Present</li>
                    <li>Category: Public Speaking, Facilitation, Personal Development</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 4 -->
    <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2>Emotion Recognition from Vocal Intonation</h2>
                  <p class="item-intro text-muted">AI that understands how you feel.</p>
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/emotion_recognition/3.jpg" alt="">
                  <p>The motivation behind this social robotics research is its value in assisting the aging population with dementia by providing social interaction. Handing the elderly with a robot for social engagement may still be hard to imagine. But the truth is that the number of social workers is declining as the population ages, and we are anticipating insufficiency in providing professional social interaction, which is an essential aspect of dementia treatment. Simply put, there will not be enough working population when the baby-boomer generation enters the age prone to dementia.</p>
 
                  <p>My research focused on enhancing the quality of interaction between a human and a robot. Interacting with robots today still feels artificial and unengaging. One way to make robot interaction less painful is for robots to have awareness of the other’s affect state. There are few ways us as humans execute emotional intelligence: facial expression, body gesture and vocal intonation. While there has been many research done to decipher facial expression, body gesture and vocal intonation has been a tricky subject. My thesis focuses on predicting emotion from vocal intonation. The overall research experience was a highly iterative process with a lot of bouncing back and forth on ideas, but it can be summarized in the following 3 steps: Obtaining Speech-to-Emotion data, Signal processing to obtain vocal intonation features, and training a Emotion-to-Vocal-Intonation prediction model. In the final stage, the resultant Vocal-Intonation-to-Emotion prediction model was combined with Emotion-to-Body-Gesture model developed by another Master student from the lab.</p>

                  <p><strong>Speech-to-Emotion Data Collection</strong> There were several online database that maps speech recordings to emotions. After analyzing them, we were not satisfied the choice of language, age variance, and the 5 emotion classes (we want to classify 9 different emotions!). By scoping the target speakers to those of a certain age group, we can anticipate higher chance of building a successful classifier. Adding variances to model the real world should come afterwards. We recorded speeches with acted emotions by lab mates without any history of acting, and assumed that it represents how the average young adult conveys emotion.</p>
                    
                  <p><strong>Training Data Curation</strong> Now with the database of speeches labeled with corresponding emotions, the creation of training data was commenced. The main task for this step is to pick the best set of voice signal features that is a good indicator of emotion. In short, “what about the voice signal carries emotion info?” And this process is experimental, an iterative process of making an educated guess from signal processing perspective and putting it through various machine learning algorithms to see which gives the highest accuracy. After many, many trial and literature review, the best feature set, or feature vector, was made of 51 features including common attributes like amplitude and natural frequency to advanced signal processing attributes like mel-frequency cepstral coefficients! Using Matlab and Python, the recorded speeches were segmented and features were extracted, resulting in a training data of 994 feature vectors with length of 51!</p>

                  <p><strong>Machine Learning!</strong> This is the validation stage of the selected feature set. I used Python to format the training data to something acceptable by Weka, the machine learning tool used for this research. Cross validation on the prediction model derived with neural network on the 994 vectors of 51 features yielded 82% accuracy in classifying a given speech to one of the 9 emotions. This model was used to build a real-time emotion classification system with Python and Weka, ready to be tested with human interaction!

                  <p><strong>BONUS: Multimodal Experimentation</strong> The Real-time Emotion Prediction via Vocal Intonation and via Body Gesture was integrated with additional machine learning work to answer the question of, “which is a better indicator of emotion in what situation?” It could be integrated with other modal of emotion, such as facial expression but this was out of our scope. Our integrated work, now the “AI that can detect emotion from vocal intonation and body gesture” in an interaction, was installed on a NAO robot developed by Softbank Robotics. The NAO robot was given dialogues to interact with people and the quality of the response was analyzed. The responses included consideration for the emotions detected, thus increasing the EQ of the robot!</p>

                  <ul class="list-inline">
                    <li>Date: Aug 2015 - Nov 2016</li>
                    <li>Category: Social Robotics, Human-Robot Interaction, Machine Learning, Software Engineering</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    

    <!-- Modal 5 -->
    <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2>Breathing Instructor app</h2>
                  <p class="item-intro text-muted">Anxiety is inevitable.</p>
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/breathing_instructor/UI1_labelled.png" alt="">
                  <p>The awareness for mindfulness was just on the rise and I was coming off fresh from working with clinicians from Centre for Addiction and Mental Health (CAMH) for my research project, “Effectiveness of Mobile Application in Smoking Cessation”, where I developed an Android app with professional insights on quitting smoking. For the Bachelor Thesis of my final year in undergrad, I worked with Professor Jonathan Rose of UofT to develop a mobile application to deliver guided breathing exercise and analyze its effectiveness in combating anxiety. Here are some of the engineering problems overcome:</p>
                   
                  <p><strong>Catching your breath: Signal processing</strong> The initial idea was to infer the breathing pattern of inhalation and exhalation based on the sound level captured with the smartphone’s microphone. Large sound level would be caused by breathing on the microphone, hence indicating inhalation and small sound level would be caused by no breath on the microphone, hence indicating exhalation. With a simple threshold calibration, I can easily classify the inhalation/exhalation of the app user! The truth couldn’t be any further from this, and the actual sound level I saw was noisy and jumping between “inhale” to “exhale” every couple milliseconds. After implementing signal processing technique to remove the noise and dictating the perfect distance to perform the breathing exercise from, successful classification was accomplished. But then a crucial problem arose: The phone had to be held in user’s face and no longer ergonomic to breath in. A headphone with microphone attachment proved to be a reasonable solution to this, being able to capture the breathing sound perfectly with the phone still in the user’s hand in a natural stance.</p>
                   
                  <p><strong>Guided breathing: UX design</strong> Learning Android development to build a functioning Android app was one thing, but I learned that making a nice-looking app that people would actually use was another animal. Beyond the general look of the app such as fonts and colors, the guidance of breathing had to be delivered visually and there was no way around creating some sort of animation. I implemented 4 user interfaces versions: sound level graphs of “target” and “user” (too science-y), flappy bird controlled with breathing, animation of inflating/deflating balloon with “target” outline, animation of inflating/deflating lung of a yoga instructor.</p>
                   
                  <p><strong>User testing: Survey</strong> The challenge of this project is that its impact was always going to be subjective. The two animation-based user interface was put under user-testing for final verdict. With the survey carefully designed to eliminate sample variances, 20 people were asked to try the exercise and answer questionnaires before and after the exercise. Here is an example questionnaire:</p>
                   
                  <p>The verdict was that the balloon animation provided a more intuitive guidance to breathing and that users felt more calm after performing the breathing exercise!</p>

                  <ul class="list-inline">
                    <li>Date: April 2015</li>
                    <li>Category: Android Development, UX, User testing</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Modal 6 -->
    <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" role="dialog" aria-hidden="true">
      <div class="modal-dialog">
        <div class="modal-content">
          <div class="close-modal" data-dismiss="modal">
            <div class="lr">
              <div class="rl"></div>
            </div>
          </div>
          <div class="container">
            <div class="row">
              <div class="col-lg-8 mx-auto">
                <div class="modal-body">
                  <!-- Project Details Go Here -->
                  <h2>Pipe Inspector Robot</h2>
                  <p class="item-intro text-muted">Building a fully autonomous robot from scratch.</p>
                  <img class="img-fluid d-block mx-auto" src="img/portfolio/pipe_inspection_robot/robot_side.jpg" alt="">
                  <p>Oh, the memories of Engsci. If there’s one course that could sum up my undergraduate program, it would be the (infamous) AER201: Engineering Design.</p>
 
                  <p>In a team of three, we built a fully-autonomous robot from scratch as a pilot solution to inspect a industrial pipe for potential radioactive leakage. For testing, a white 10m-long pipe with circular cross-sectional area of 50cm diameter marked with black spots that represents problematic leakage was used. The pipe was elevated about 15 cm from the ground by two pillars and the ask was to perform the inspection with the body of the robot positioned on one side of the pipe throughout the process. The robot must also start by locating the pipe and returning to the starting position upon inspection completion and report the total number of markers found and their respective positions along the length and circumference of the cross-section.</p>
 
                  <p>As the circuit specialist of the team, I fabricated all the electrical circuits including the marker sensor, pillar sensor, motor control, signal conditioner, and the motherboard with microcontroller that connects the sensor to the actuators. This was integrated with the microcontroller programmed by the programmer member and the chassis built by the mechanic member. It was during the integration of these subcomponents when unexpected challenges arose and consequently turned me into a believer in ALWAYS allocating ample time for system integration.</p>
 
                  <p>Our complete robot features a main body that holds the input keypad, microcontroller and the circuitry hub supported by 2 motorized wheels and a following non-motorized tail wheel. There is an arm extending to its right side which suspends the circular ring of marker sensors. Here are some of the challenges and the corresponding design decisions, which fundamentally made our robot, Jackattack, unique from others.</p>
                   
                  <p><strong>Moving straight: Follow the pipe!</strong>
                  Getting the robot to move in a straight line at first seems like an easy task, but it’s not. The range of motors available forced us to use two actuators, whose torque had to be sync’ed in terms of voltages energy sent and calibrated to manufacturing variances. This problem was compounded by the consideration of different surface types and highly asymmetrical chassis that resulted in uneven distribution of the weight and ultimately uneven friction made by the wheels. Our solution was to use a distance sensor and precision with pulse-width modulation (or PWM, a way to send power signal to actuators) to maintain certain space between the robot and pipe of interest to not just move straight, but to follow the pipe!</p>
                   
                  <p><strong>Overcoming the pillars: Springs!</strong>
                  The ability to move along the pipe is great and all, but on the way, there are obstacles in the form of supporting pillars. Inspired by the idea of doors that closes itself, we made the bottom portion of the sensing ring a flap that can open and close by hitting the pillars by using a spring! Hydraulic-based springs would have decreased the compressive stress to the rest of the body and would’ve been a more faithful duplication of the damping effect in self-closing doors, but we had underestimated calibration at that point :)</p>
                   
                  <p><strong>Turning exactly 180 degrees: Felt strip!</strong>
                  We finally made it through the pipe. Now we gotta go back past the starting line! Simply reversing with the pipe in the sensor ring and the tail wheel was infeasible. So we needed turn 180 degrees and trust the ability to drive somewhat straight. Turning 180 degrees consistently without any feedback signal was almost impossible. The tail wheel created highly variant friction that nullified all the calibration effort put into the motorized front wheels. And then an idea sparked: felt strips on the following tail wheel! The texture of felt strips made the variant friction negligible, which led to consistent amount of friction which we can calibrate for.</p>
                   
                  <p><strong>Markers in the shadow: Lights!</strong>
                  Counting the markers wasn’t an easy task either. Particularly, when marker sensing seemed to be working, we noticed that it wasn’t reading the markers on the bottom along the pipe. We realized that it was poorly lit on the bottom and special calibration was need for the bottom sensors. But because the bottom sensors were on a moving component (i.e. the springed door), increasing sensitivity would cause false positives when going through the pillar. To avoid another calibration-as-a-solution, we coupled the light sensor with an LED. By bringing light to the shadow, we normalized the marker-to-pipe color ratio and the light sensors were able to pick up the bottom markers reliably.</p>
                   
                  <p><strong>Not enough microcontroller I/O pins: Code with circuits!</strong>
                  At this point, there are 20 sensors and two actuators and one keypad for the microcontroller to manage, in addition to powering them! Luckily, we initially overestimated the number of components to be used and realized the insufficient number of I/O pins to connect them. We moved a lot of microcontroller logic to circuit level in order to decrease the number of signals required by microcontroller. For example, instead of sending 16 bits of signals from the 16 markers sensors on the sensor ring, the 16 signals were put through custom 16-to-4-bit binary encoder and series of OR gates, for signaling “marker found” interrupt and circumferential, we were able to cut down the required number of input pins from 16 to 5. Solving these logics at hardware level led to faster computation.
                   
                  <p>Find more on the <a href="http://aer201.aerospace.utoronto.ca/history/team.aspx?ID=16&Team=W16&Project=Project3&Year=2012">AER201 website!</a></p>

                  <ul class="list-inline">
                    <li>Date: April 2012</li>
                    <li>Category: Engineering Design, Robots, Circuits, Microcontroller</li>
                  </ul>
                  <button class="btn btn-primary" data-dismiss="modal" type="button">
                    <i class="fa fa-times"></i>
                    Close Project</button>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/popper/popper.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>

    <!-- Contact form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Custom scripts for this template -->
    <script src="js/agency.min.js"></script>

  </body>

</html>
